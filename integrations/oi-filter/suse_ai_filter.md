# Changelog

## Version 1.1.0

What's new:

* Support for vLLM as inference server.

Fixes:

* Fix failure to process OpenAI payloads.

## Version 1.0.0

What's new:

* Infer tracing data and metrics for user chats with Ollama models.
* Custom configurations through the UI or environment variables.
